{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMBvCyuFclkx",
        "outputId": "e5870e67-08d4-4c97-ae3b-e7340a84a63d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "\n",
        "(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = (x_train.astype(np.float32) - 127.5) / 127.5  # Normalize to [-1, 1]\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "\n",
        "num_classes = 10\n",
        "image_shape = (28, 28, 1)\n",
        "noise_dim = 100\n",
        "\n",
        "y_train_ohe = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "\n",
        "\n",
        "def build_generator():\n",
        "    noise_input = layers.Input(shape=(noise_dim,))\n",
        "    label_input = layers.Input(shape=(num_classes,))\n",
        "\n",
        "    x = layers.Concatenate()([noise_input, label_input])\n",
        "    x = layers.Dense(7 * 7 * 512, use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Reshape((7, 7, 512))(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(256, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    img = layers.Conv2DTranspose(1, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh')(x)\n",
        "\n",
        "    return tf.keras.Model([noise_input, label_input], img)\n",
        "\n",
        "def build_discriminator():\n",
        "    img_input = layers.Input(shape=image_shape)\n",
        "    label_input = layers.Input(shape=(num_classes,))\n",
        "    label_expanded = layers.Dense(np.prod(image_shape))(label_input)\n",
        "    label_expanded = layers.Reshape(image_shape)(label_expanded)\n",
        "\n",
        "    x = layers.Concatenate()([img_input, label_expanded])\n",
        "    x = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    return tf.keras.Model([img_input, label_input], output)\n",
        "\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output) * 0.9, real_output)  # Label smoothing\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "\n",
        "initial_lr = 1e-4\n",
        "generator_optimizer = tf.keras.optimizers.Adam(initial_lr)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(initial_lr)\n",
        "\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator([noise, labels], training=True)\n",
        "\n",
        "        real_output = discriminator([images, labels], training=True)\n",
        "        fake_output = discriminator([generated_images, labels], training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input, test_labels):\n",
        "    predictions = model([test_input, test_labels], training=False)\n",
        "    predictions = (predictions + 1) / 2.0\n",
        "\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig(f'image_at_epoch_{epoch:04d}.png')\n",
        "    plt.close()\n",
        "\n",
        "EPOCHS = 9000  # Training time\n",
        "BATCH_SIZE = 256\n",
        "num_examples_to_generate = 16\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "fixed_labels = np.eye(num_classes)[np.random.choice(num_classes, num_examples_to_generate)]\n",
        "fixed_labels = tf.convert_to_tensor(fixed_labels, dtype=tf.float32)\n",
        "\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    idx = np.random.randint(0, x_train.shape[0], BATCH_SIZE)\n",
        "    real_images = x_train[idx]\n",
        "    real_labels = y_train_ohe[idx]\n",
        "\n",
        "    gen_loss, disc_loss = train_step(real_images, real_labels)\n",
        "\n",
        "    # تقليل Learning rate بعد 1000 epochs\n",
        "    if epoch == 1000:\n",
        "        generator_optimizer.learning_rate = 1e-5\n",
        "        discriminator_optimizer.learning_rate = 1e-5\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        generate_and_save_images(generator, epoch, seed, fixed_labels)\n",
        "        print(f'Epoch {epoch}, Gen Loss: {gen_loss.numpy()}, Disc Loss: {disc_loss.numpy()}')\n",
        "\n",
        "\n",
        "generator.save(\"CGAN_generator_model_v2.h5\")\n",
        "print(\"✅ Generator model saved as CGAN_generator_model_v2.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBm0AME3OvJV",
        "outputId": "beb1aea9-feac-4c1f-cb65-27d938d701e1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100, Gen Loss: 0.8819351196289062, Disc Loss: 1.2700002193450928\n",
            "Epoch 200, Gen Loss: 0.7923362851142883, Disc Loss: 1.3507447242736816\n",
            "Epoch 300, Gen Loss: 0.7834339737892151, Disc Loss: 1.3666331768035889\n",
            "Epoch 400, Gen Loss: 0.7517690658569336, Disc Loss: 1.4688674211502075\n",
            "Epoch 500, Gen Loss: 0.8042851686477661, Disc Loss: 1.340198040008545\n",
            "Epoch 600, Gen Loss: 0.9833194613456726, Disc Loss: 1.15423583984375\n",
            "Epoch 700, Gen Loss: 0.9458767175674438, Disc Loss: 1.3649787902832031\n",
            "Epoch 800, Gen Loss: 0.7623312473297119, Disc Loss: 1.6742689609527588\n",
            "Epoch 900, Gen Loss: 0.8232691287994385, Disc Loss: 1.27484130859375\n",
            "Epoch 1000, Gen Loss: 0.7359393835067749, Disc Loss: 1.5011640787124634\n",
            "Epoch 1100, Gen Loss: 0.7936621308326721, Disc Loss: 1.4088261127471924\n",
            "Epoch 1200, Gen Loss: 0.8211030960083008, Disc Loss: 1.3724453449249268\n",
            "Epoch 1300, Gen Loss: 0.8271937370300293, Disc Loss: 1.3667688369750977\n",
            "Epoch 1400, Gen Loss: 0.8264487981796265, Disc Loss: 1.4061996936798096\n",
            "Epoch 1500, Gen Loss: 0.8550834655761719, Disc Loss: 1.3490651845932007\n",
            "Epoch 1600, Gen Loss: 0.8644992113113403, Disc Loss: 1.3456566333770752\n",
            "Epoch 1700, Gen Loss: 0.8435627222061157, Disc Loss: 1.354392647743225\n",
            "Epoch 1800, Gen Loss: 0.8061401844024658, Disc Loss: 1.3805444240570068\n",
            "Epoch 1900, Gen Loss: 0.8153012990951538, Disc Loss: 1.3781194686889648\n",
            "Epoch 2000, Gen Loss: 0.8254256248474121, Disc Loss: 1.3615694046020508\n",
            "Epoch 2100, Gen Loss: 0.8183725476264954, Disc Loss: 1.3706917762756348\n",
            "Epoch 2200, Gen Loss: 0.8206645250320435, Disc Loss: 1.3418806791305542\n",
            "Epoch 2300, Gen Loss: 0.80870121717453, Disc Loss: 1.355139970779419\n",
            "Epoch 2400, Gen Loss: 0.8150694966316223, Disc Loss: 1.3592166900634766\n",
            "Epoch 2500, Gen Loss: 0.8295642733573914, Disc Loss: 1.347425937652588\n",
            "Epoch 2600, Gen Loss: 0.8391934037208557, Disc Loss: 1.3455877304077148\n",
            "Epoch 2700, Gen Loss: 0.7867680788040161, Disc Loss: 1.3905975818634033\n",
            "Epoch 2800, Gen Loss: 0.7976717352867126, Disc Loss: 1.3728587627410889\n",
            "Epoch 2900, Gen Loss: 0.8335927724838257, Disc Loss: 1.3358736038208008\n",
            "Epoch 3000, Gen Loss: 0.805435299873352, Disc Loss: 1.3785159587860107\n",
            "Epoch 3100, Gen Loss: 0.8007047176361084, Disc Loss: 1.3825806379318237\n",
            "Epoch 3200, Gen Loss: 0.8209987878799438, Disc Loss: 1.353642225265503\n",
            "Epoch 3300, Gen Loss: 0.8153284192085266, Disc Loss: 1.3583648204803467\n",
            "Epoch 3400, Gen Loss: 0.8053492307662964, Disc Loss: 1.3654332160949707\n",
            "Epoch 3500, Gen Loss: 0.8135262727737427, Disc Loss: 1.3422106504440308\n",
            "Epoch 3600, Gen Loss: 0.8135697245597839, Disc Loss: 1.3545112609863281\n",
            "Epoch 3700, Gen Loss: 0.8233718872070312, Disc Loss: 1.335702896118164\n",
            "Epoch 3800, Gen Loss: 0.8148606419563293, Disc Loss: 1.358403205871582\n",
            "Epoch 3900, Gen Loss: 0.8023696541786194, Disc Loss: 1.37680184841156\n",
            "Epoch 4000, Gen Loss: 0.8166400194168091, Disc Loss: 1.3386656045913696\n",
            "Epoch 4100, Gen Loss: 0.827599048614502, Disc Loss: 1.3446300029754639\n",
            "Epoch 4200, Gen Loss: 0.8230500221252441, Disc Loss: 1.3569539785385132\n",
            "Epoch 4300, Gen Loss: 0.7991427779197693, Disc Loss: 1.3816463947296143\n",
            "Epoch 4400, Gen Loss: 0.8211574554443359, Disc Loss: 1.3797569274902344\n",
            "Epoch 4500, Gen Loss: 0.7962577939033508, Disc Loss: 1.3715531826019287\n",
            "Epoch 4600, Gen Loss: 0.8247241377830505, Disc Loss: 1.3411717414855957\n",
            "Epoch 4700, Gen Loss: 0.824364185333252, Disc Loss: 1.3533310890197754\n",
            "Epoch 4800, Gen Loss: 0.7988445162773132, Disc Loss: 1.3727327585220337\n",
            "Epoch 4900, Gen Loss: 0.8105418682098389, Disc Loss: 1.3620078563690186\n",
            "Epoch 5000, Gen Loss: 0.819300651550293, Disc Loss: 1.3635790348052979\n",
            "Epoch 5100, Gen Loss: 0.8199527859687805, Disc Loss: 1.3570830821990967\n",
            "Epoch 5200, Gen Loss: 0.8216996788978577, Disc Loss: 1.3536287546157837\n",
            "Epoch 5300, Gen Loss: 0.8236132860183716, Disc Loss: 1.369110107421875\n",
            "Epoch 5400, Gen Loss: 0.8020592331886292, Disc Loss: 1.3776614665985107\n",
            "Epoch 5500, Gen Loss: 0.8236756324768066, Disc Loss: 1.349480152130127\n",
            "Epoch 5600, Gen Loss: 0.8182725310325623, Disc Loss: 1.3561369180679321\n",
            "Epoch 5700, Gen Loss: 0.7853183746337891, Disc Loss: 1.3925578594207764\n",
            "Epoch 5800, Gen Loss: 0.8202158212661743, Disc Loss: 1.3685611486434937\n",
            "Epoch 5900, Gen Loss: 0.8341010212898254, Disc Loss: 1.3480234146118164\n",
            "Epoch 6000, Gen Loss: 0.7980161905288696, Disc Loss: 1.3758025169372559\n",
            "Epoch 6100, Gen Loss: 0.8094552755355835, Disc Loss: 1.3642361164093018\n",
            "Epoch 6200, Gen Loss: 0.8128888010978699, Disc Loss: 1.3448759317398071\n",
            "Epoch 6300, Gen Loss: 0.8184158205986023, Disc Loss: 1.368133783340454\n",
            "Epoch 6400, Gen Loss: 0.8392052054405212, Disc Loss: 1.365104079246521\n",
            "Epoch 6500, Gen Loss: 0.843914270401001, Disc Loss: 1.3768398761749268\n",
            "Epoch 6600, Gen Loss: 0.8348059058189392, Disc Loss: 1.3710399866104126\n",
            "Epoch 6700, Gen Loss: 0.8071020245552063, Disc Loss: 1.3594365119934082\n",
            "Epoch 6800, Gen Loss: 0.7690410017967224, Disc Loss: 1.3542344570159912\n",
            "Epoch 6900, Gen Loss: 0.7752853035926819, Disc Loss: 1.3636231422424316\n",
            "Epoch 7000, Gen Loss: 0.7994655966758728, Disc Loss: 1.3662647008895874\n",
            "Epoch 7100, Gen Loss: 0.8170492053031921, Disc Loss: 1.3513164520263672\n",
            "Epoch 7200, Gen Loss: 0.8172501921653748, Disc Loss: 1.3645821809768677\n",
            "Epoch 7300, Gen Loss: 0.821524977684021, Disc Loss: 1.3620147705078125\n",
            "Epoch 7400, Gen Loss: 0.8270250558853149, Disc Loss: 1.3649299144744873\n",
            "Epoch 7500, Gen Loss: 0.815299391746521, Disc Loss: 1.3599610328674316\n",
            "Epoch 7600, Gen Loss: 0.8362855911254883, Disc Loss: 1.3475072383880615\n",
            "Epoch 7700, Gen Loss: 0.8068702816963196, Disc Loss: 1.3478732109069824\n",
            "Epoch 7800, Gen Loss: 0.8089800477027893, Disc Loss: 1.3621306419372559\n",
            "Epoch 7900, Gen Loss: 0.8232555389404297, Disc Loss: 1.3548892736434937\n",
            "Epoch 8000, Gen Loss: 0.8339537978172302, Disc Loss: 1.3468830585479736\n",
            "Epoch 8100, Gen Loss: 0.8290095329284668, Disc Loss: 1.343855381011963\n",
            "Epoch 8200, Gen Loss: 0.8323448896408081, Disc Loss: 1.3391424417495728\n",
            "Epoch 8300, Gen Loss: 0.9326986074447632, Disc Loss: 1.4075909852981567\n",
            "Epoch 8400, Gen Loss: 0.6768254637718201, Disc Loss: 1.4220644235610962\n",
            "Epoch 8500, Gen Loss: 0.878905177116394, Disc Loss: 1.339530110359192\n",
            "Epoch 8600, Gen Loss: 0.8168723583221436, Disc Loss: 1.3722584247589111\n",
            "Epoch 8700, Gen Loss: 0.8265953063964844, Disc Loss: 1.3429484367370605\n",
            "Epoch 8800, Gen Loss: 0.8465187549591064, Disc Loss: 1.3219879865646362\n",
            "Epoch 8900, Gen Loss: 0.8339954614639282, Disc Loss: 1.3418662548065186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9000, Gen Loss: 0.8291915655136108, Disc Loss: 1.356248140335083\n",
            "✅ Generator model saved as CGAN_generator_model_v2.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"CGAN_generator_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "yArL9LtrOzeh",
        "outputId": "404208b0-41aa-4c46-89bf-438867aeaaaa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bfdb3edd-2257-4c17-9518-6f918f1ce88e\", \"CGAN_generator_model.h5\", 9870976)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "generator = load_model(\"CGAN_generator_model.h5\")\n",
        "\n",
        "\n",
        "digit = 9\n",
        "noise = tf.random.normal([5, noise_dim])\n",
        "label = tf.keras.utils.to_categorical([digit]*5, num_classes)\n",
        "\n",
        "generated_images = generator.predict([noise, label])\n",
        "\n",
        "for img in generated_images:\n",
        "    plt.imshow(((img + 1) / 2.0).squeeze(), cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-SARJzGOO87c",
        "outputId": "6d5d35dc-2f31-4369-9984-937e99ae113a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAACiVJREFUeJzt3D+o1fUfx/HP996jN7WoSAUxuBTVIlFz2CA4aCFo1NwiRk21tLVE0WaTri0RNKqQQ4ObgQ7a2KTDhVIQta7ctKPf3/R70Y9fP/q+vz8990+Px3xenC/Xc8/zfgY/Xd/3fQOA1trcaj8AAGuHKAAQogBAiAIAIQoAhCgAEKIAQIgCADEZ+sKu6x7lcwB/Yy3/Dvo/sOvDkH8nJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAGHwhHrC6XDrHLDgpABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQk9V+AFgrHnvssfLm3XffLW+effbZ8qa11r7//vvy5vz58+XNdDotb9g4nBQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAouv7vh/0wq571M8Cf+nxxx8vb7799tvy5sCBA+XN3Nza/rtqeXm5vHn99dfLm8uXL5c3zN6Qr/u1/YkGYKZEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACAmq/0ArE9jbs09efLkqPfas2dPefPjjz+WN8ePHy9vjhw5Ut5s3769vGmttS1btpQ3d+/eLW8WFxfLmzE/74EXNDNjTgoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA0fUDb6UacwEa68PCwkJ58+uvv5Y3mzdvLm9aa+2HH34ob1577bVR77XRjPmZ79q1q7y5d+9eebNp06byprXWjh49Wt68+eab5c1nn31W3pw5c6a8aa216XQ6alc15OveSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgXIi3wYz5d/r999/LmzEXrS0vL5c3rbX2xBNPjNoxOx9//HF58+mnn456rzEX6d2/f7+82bt3b3lz4cKF8maWXIgHQIkoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCADFZ7Qfg4XrllVfKmzEXjJ06daq8OXz4cHnD7I25VPGdd94pbxYWFsqb1sZdbvfFF1+UNxcvXixvNgInBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQCi6/u+H/TCETcnMnuvvvpqeXPmzJnyZnFxsbx58OBBecPsPfnkk+XN0tJSebNt27byprXWfv755/LmpZdeKm/u3LlT3qx1Q77unRQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAYrLaD8DD9c0335Q3W7ZsKW9cbrc+zM3V/+67ePFiebN169by5o8//ihvWmvtww8/LG9WVlZGvdc/kZMCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQLgQb43qum7U7sUXXyxvxlya9tFHH5U3X3/9dXnTWmu3bt0atauaTqflTd/35c38/Hx501pru3fvLm++/PLL8ub5558vb8ZckHj27NnyprXWTp06Vd6M+Xf6p3JSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIiuH3hT1NgL2hhnYWFh1G55ebm8mUzq9yKOuQBt7GdozGVmYzYnTpwob7766qvy5rfffitvWmvt/fffL2/eeuut8mZxcbG8uXLlSnmzf//+8qa11q5evTpqx7DfCycFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgKjfhMZMjLlwrrXWLl26VN7s2LGjvBlz8d6Y92mtta1bt5Y3Y35+e/bsKW8OHjxY3pw7d668aa21W7dulTdPP/10eTPmMsHNmzeXN0tLS+UNj56TAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDR9QOvROy67lE/C3/yzDPPzOy9bty4MbP3mpWFhYXy5tChQ+XN559/Xt5Mp9PyprVxN5E+99xz5c38/Hx5c/v27fLmqaeeKm/4/wz5undSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIjJaj8Af+3mzZujdg8ePHjIT7I+3b17t7xZWloqb1544YXyZuAdlP9lZWWlvBlzkeWY53vvvffKG9YmJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAcCHeGuViu9l74403ypu5ufrfVdPptLxprbX79++XN999911588knn5Q3ly9fLm9Ym5wUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAKLr+74f9MKue9TPAqvql19+KW927tw5k/dprbV9+/aVNz/99NOo92JjGvJ176QAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEJPVfgD4O2MuY3z77bfLm+3bt5c3A++T/A+nT58ub1pzuR2z4aQAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQHT9wGsex9xUCX829jN0/Pjx8ubYsWPlzfz8fHlz5cqV8ubll18ub1prbTqdjtrBvw35undSACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIjJaj8A/J2VlZXyZszle9euXStvPvjgg/LGxXasZU4KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCANH1fd8PeuGIC8bgYZibq//tcvDgwfJm9+7d5c3Zs2fLm6WlpfKmtdYG/qrC/zTkM+SkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABAuxGND2rRpU3mzc+fO8mYymZQ3t2/fLm/G7lyix5+5EA+AElEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQAiPoVj7AOTKfT8ub69evlza5du8qbO3fulDcwK04KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCANH1fd8PemHXPepngXVnzO/FwF85eOiGfPacFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBiMvSFLvEC2PicFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIh/AUWKjS/DIqKLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}